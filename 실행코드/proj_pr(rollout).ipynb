{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM/aDT/aExyXRNKeZdHAJBc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# --- 0) 경로 변수 먼저 정의 ---\n","import os, glob, shutil\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split\n","\n","BASE = '/content/drive/MyDrive/인공지능 튜플'   # <- 구글 드라이브 루트(마운트 필요)\n","DATA_DIR = os.path.join(BASE, 'OriginalDataset')  # <- 원본(클래스 폴더만 있는 단일 루트)\n","SPLIT = '/content/dataset_hybrid'                 # <- 분할본을 만들 위치(로컬)\n","\n","assert os.path.isdir(DATA_DIR), f\"원본 데이터 폴더가 없습니다: {DATA_DIR}\\n드라이브 마운트/경로를 확인하세요.\"\n","\n","# --- 1) train/val/test 물리 분할 생성(없으면 생성, 있으면 스킵) ---\n","R_TRAIN, R_VAL, R_TEST = 0.8, 0.1, 0.1\n","SEED = 123\n","EXTS = ('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')\n","\n","if not (os.path.isdir(os.path.join(SPLIT, 'train')) and\n","        os.path.isdir(os.path.join(SPLIT, 'val')) and\n","        os.path.isdir(os.path.join(SPLIT, 'test'))):\n","    classes = [d for d in sorted(os.listdir(DATA_DIR)) if os.path.isdir(os.path.join(DATA_DIR, d))]\n","    print(\"클래스:\", classes)\n","    for split in ['train','val','test']:\n","        for c in classes:\n","            os.makedirs(os.path.join(SPLIT, split, c), exist_ok=True)\n","\n","    for c in classes:\n","        files = []\n","        for e in EXTS:\n","            files += glob.glob(os.path.join(DATA_DIR, c, f'*{e}'))\n","        files = sorted(files)\n","        if len(files) == 0:\n","            print(f\"[warn] '{c}' 클래스에 이미지가 없습니다.\")\n","            continue\n","\n","        train_files, rest = train_test_split(files, test_size=(1 - R_TRAIN), random_state=SEED, shuffle=True)\n","        val_files, test_files = train_test_split(rest, test_size=R_TEST/(R_VAL+R_TEST), random_state=SEED, shuffle=True)\n","\n","        for src_list, dst_split in [(train_files,'train'), (val_files,'val'), (test_files,'test')]:\n","            dst_dir = os.path.join(SPLIT, dst_split, c)\n","            for src in src_list:\n","                shutil.copy2(src, os.path.join(dst_dir, os.path.basename(src)))\n","    print(f\"[ok] 분할 생성 완료: {SPLIT}\")\n","else:\n","    print(f\"[skip] 이미 분할 폴더가 존재합니다: {SPLIT}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwG7oCN-o1Je","executionInfo":{"status":"ok","timestamp":1756367396367,"user_tz":-540,"elapsed":195137,"user":{"displayName":"박명세","userId":"14359745111210594896"}},"outputId":"717f0e51-8346-4566-8699-a16c4ad72ff4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["클래스: ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n","[ok] 분할 생성 완료: /content/dataset_hybrid\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqzPtLY6DhlK","executionInfo":{"status":"ok","timestamp":1756368314579,"user_tz":-540,"elapsed":182964,"user":{"displayName":"박명세","userId":"14359745111210594896"}},"outputId":"8a5c8df6-82a9-4b79-808e-2426f16b06d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[CKPT candidates]\n"," - best_hybrid_by_f1.weights.h5 (347782520 bytes)\n"," - best_hybrid.keras (0 bytes)\n"," - best_hybrid_by_f1.keras (0 bytes)\n"," - best_hybrid.h5 (347652312 bytes)\n"," - best_balanced_focal.h5 (74671448 bytes)\n"," - best_res288.h5 (75275608 bytes)\n","[i] weights-only HDF5 → build + load_weights\n","[✓] load_weights: best_hybrid_by_f1.weights.h5\n","Found 643 files belonging to 4 classes.\n","Found 644 files belonging to 4 classes.\n","Classes: ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n","Saved: /content/drive/MyDrive/인공지능 튜플/proj_pr/out/rollout/val_rollout_grid_masked.png\n","Saved: /content/drive/MyDrive/인공지능 튜플/proj_pr/out/rollout/test_rollout_grid_masked.png\n","[diag] grid HxW=5x5, T=25, ok=True\n","[diag] brain-focus ratio=1.000 (권장 ≥ 0.90)\n","[TTA:none       ] acc=0.5047  macroF1=0.3538  ROC-AUC=0.7859  48.5 ms/img\n","[TTA:hflip      ] acc=0.5124  macroF1=0.3568  ROC-AUC=0.7878  31.8 ms/img\n","[TTA:5crop      ] acc=0.5078  macroF1=0.3682  ROC-AUC=0.7750  63.6 ms/img\n","[TTA:hflip+5crop] acc=0.5062  macroF1=0.3709  ROC-AUC=0.7792  92.8 ms/img\n","Saved CSV: /content/drive/MyDrive/인공지능 튜플/proj_pr/out/tta_results.csv\n","Artifacts saved in: /content/drive/MyDrive/인공지능 튜플/proj_pr/out\n"]}],"source":["# ============================================================\n","# CNN–ViT Hybrid (ResNet50 -> ViT) | Robust CKPT + Masked Rollout + TTA\n","# - CKPT 우선순위/형식 감지 로더: *.weights.h5 > .keras(zip) > .h5\n","# - Validation/Test 로더 (증강 X, [0,1] 스케일)\n","# - Attention Rollout (두상 마스크 내부 정규화 + 배경 알파=0)\n","# - gt|pred 타이틀 그리드 저장 + 진단 지표(brain-focus ratio)\n","# - TTA 정책별 성능 비교 (CSV/Confusion Matrix 저장)\n","# 저장 경로: /content/drive/MyDrive/인공지능 튜플/proj_pr/out/\n","# ============================================================\n","import os, glob, time, zipfile, csv\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_auc_score\n","\n","# -------------------\n","# 0) 경로/상수\n","# -------------------\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","BASE  = '/content/drive/MyDrive/인공지능 튜플'\n","SPLIT = '/content/dataset_hybrid'   # val/ , test/ 가 있는 경로\n","OUT   = f'{BASE}/proj_pr/out'\n","os.makedirs(OUT, exist_ok=True)\n","\n","IMG_SIZE    = (288, 288)\n","BATCH       = 32\n","SEED        = 123\n","NUM_CLASSES = 4\n","\n","tf.keras.utils.set_random_seed(SEED)\n","\n","# -------------------\n","# 1) 모델 정의 (직렬화 가능)\n","# -------------------\n","class PositionalEmbedding2D(layers.Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.pos = None\n","    def build(self, input_shape):\n","        H, W, D = input_shape[1], input_shape[2], input_shape[3]\n","        if None in (H, W, D):\n","            raise ValueError(f\"PositionalEmbedding2D needs static H,W,D, got {input_shape}\")\n","        self.pos = self.add_weight(\n","            name=\"pos2d\",\n","            shape=(H, W, D),\n","            initializer=keras.initializers.RandomNormal(stddev=0.02),\n","            trainable=True,\n","        )\n","    def call(self, x):  # x: (B,H,W,D)\n","        return x + self.pos\n","    def get_config(self):\n","        return super().get_config()\n","\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, num_heads=4, mlp_ratio=4.0, drop=0.1, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.num_heads = num_heads\n","        self.mlp_ratio = mlp_ratio\n","        self.drop = drop\n","        self.n1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.mha= layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim//num_heads, dropout=drop)\n","        self.d1 = layers.Dropout(drop)\n","        self.n2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.mlp= keras.Sequential([\n","            layers.Dense(int(embed_dim*mlp_ratio), activation=tf.nn.gelu),\n","            layers.Dropout(drop),\n","            layers.Dense(embed_dim),\n","            layers.Dropout(drop),\n","        ])\n","    def call(self, x, training=False):\n","        h = self.mha(self.n1(x), self.n1(x), training=training)\n","        x = x + self.d1(h, training=training)\n","        x = x + self.mlp(self.n2(x), training=training)\n","        return x\n","    def get_config(self):\n","        cfg = super().get_config()\n","        cfg.update(dict(embed_dim=self.embed_dim, num_heads=self.num_heads,\n","                        mlp_ratio=self.mlp_ratio, drop=self.drop))\n","        return cfg\n","\n","def build_hybrid(input_shape, num_classes, embed_dim=256, vit_blocks=4, heads=4, drop=0.1):\n","    inp = layers.Input(input_shape)\n","    x = keras.applications.resnet.preprocess_input(inp*255.0)\n","    backbone = keras.applications.ResNet50(include_top=False, weights='imagenet', name='resnet50')\n","    feat = backbone(x, training=False)\n","\n","    tok = layers.Conv2D(embed_dim, 2, strides=2, padding='same', name='patch_embed_conv')(feat)\n","    tok = layers.BatchNormalization(name='patch_embed_bn')(tok)\n","    tok = layers.Activation('gelu', name='patch_embed_gelu')(tok)\n","    tok = layers.Dropout(drop, name='patch_embed_dropout')(tok)\n","\n","    tok = PositionalEmbedding2D(name='pos2d')(tok)\n","    H, W = tok.shape[1], tok.shape[2]\n","    tokens = layers.Reshape((H*W, embed_dim), name='tokens')(tok)\n","    z = layers.Dropout(drop, name='tokens_dropout')(tokens)\n","\n","    for i in range(vit_blocks):\n","        z = TransformerEncoder(embed_dim=embed_dim, num_heads=heads, mlp_ratio=4.0, drop=drop, name=f'encoder_{i}')(z)\n","\n","    z = layers.GlobalAveragePooling1D(name='gap')(z)\n","    z = layers.Dropout(0.5, name='head_drop1')(z)\n","    z = layers.Dense(512, activation='gelu', name='head_dense')(z)\n","    z = layers.Dropout(0.4, name='head_drop2')(z)\n","    out = layers.Dense(num_classes, activation='softmax', name='classifier')(z)\n","\n","    model = keras.Model(inp, out, name='ResNet50_ViT_hybrid')\n","    for l in backbone.layers:\n","        if isinstance(l, layers.BatchNormalization): l.trainable = False\n","    return model\n","\n","# -------------------\n","# 2) CKPT 선택/로딩 (우선순위 + 형식 감지)\n","# -------------------\n","def pick_ckpt(out_dir):\n","    # 1순위: *.weights.h5  2순위: .keras(zip)  3순위: .h5\n","    w = sorted(glob.glob(os.path.join(out_dir, '*.weights.h5')), key=os.path.getmtime, reverse=True)\n","    k = sorted(glob.glob(os.path.join(out_dir, '*.keras')), key=os.path.getmtime, reverse=True)\n","    h = sorted([p for p in glob.glob(os.path.join(out_dir, '*.h5')) if not p.endswith('.weights.h5')], key=os.path.getmtime, reverse=True)\n","    cand = (w + k + h)\n","    print(\"[CKPT candidates]\")\n","    for p in cand[:8]:\n","        sz = os.path.getsize(p) if os.path.exists(p) else -1\n","        print(\" -\", os.path.basename(p), f\"({sz} bytes)\")\n","    return cand[0] if cand else None\n","\n","def is_valid_keras_zip(path):  # .keras가 진짜 zip인지 확인\n","    try:\n","        return zipfile.is_zipfile(path)\n","    except:\n","        return False\n","\n","CKPT = pick_ckpt(OUT)\n","assert CKPT is not None, f\"체크포인트 없음: {OUT}\"\n","\n","roll_model = None\n","if CKPT.endswith('.weights.h5'):\n","    print(\"[i] weights-only HDF5 → build + load_weights\")\n","    tmp = build_hybrid(IMG_SIZE+(3,), NUM_CLASSES, embed_dim=256, vit_blocks=4, heads=4, drop=0.1)\n","    tmp.load_weights(CKPT)\n","    roll_model = tmp\n","    print(\"[✓] load_weights:\", os.path.basename(CKPT))\n","\n","elif CKPT.endswith('.keras'):\n","    if is_valid_keras_zip(CKPT):\n","        print(\"[i] valid .keras zip → load_model\")\n","        roll_model = keras.models.load_model(\n","            CKPT, compile=False,\n","            custom_objects={'PositionalEmbedding2D': PositionalEmbedding2D,\n","                            'TransformerEncoder': TransformerEncoder}\n","        )\n","        print(\"[✓] load_model(.keras):\", os.path.basename(CKPT))\n","    else:\n","        print(\"[!] .keras가 zip 포맷이 아님 → weights로 시도\")\n","        tmp = build_hybrid(IMG_SIZE+(3,), NUM_CLASSES, embed_dim=256, vit_blocks=4, heads=4, drop=0.1)\n","        tmp.load_weights(CKPT)\n","        roll_model = tmp\n","        print(\"[✓] load_weights(.keras명):\", os.path.basename(CKPT))\n","else:  # 기타 .h5\n","    print(\"[i] .h5 감지 → load_model 시도, 실패 시 weights로 재시도\")\n","    try:\n","        roll_model = keras.models.load_model(\n","            CKPT, compile=False,\n","            custom_objects={'PositionalEmbedding2D': PositionalEmbedding2D,\n","                            'TransformerEncoder': TransformerEncoder}\n","        )\n","        print(\"[✓] load_model(.h5):\", os.path.basename(CKPT))\n","    except Exception as e:\n","        print(\"[!] load_model 실패 → load_weights:\", e)\n","        tmp = build_hybrid(IMG_SIZE+(3,), NUM_CLASSES, embed_dim=256, vit_blocks=4, heads=4, drop=0.1)\n","        tmp.load_weights(CKPT)\n","        roll_model = tmp\n","        print(\"[✓] load_weights(.h5):\", os.path.basename(CKPT))\n","\n","# -------------------\n","# 3) Val/Test 로더 (증강 X, [0,1])\n","# -------------------\n","val_raw = tf.keras.utils.image_dataset_from_directory(\n","    os.path.join(SPLIT, 'val'), image_size=IMG_SIZE, batch_size=BATCH, shuffle=False)\n","test_raw = tf.keras.utils.image_dataset_from_directory(\n","    os.path.join(SPLIT, 'test'), image_size=IMG_SIZE, batch_size=BATCH, shuffle=False)\n","\n","classes = val_raw.class_names\n","val_ds  = val_raw.map(lambda x,y: (x/255.0, tf.one_hot(y, NUM_CLASSES))).prefetch(tf.data.AUTOTUNE)\n","test_ds = test_raw.map(lambda x,y: (x/255.0, tf.one_hot(y, NUM_CLASSES))).prefetch(tf.data.AUTOTUNE)\n","print(\"Classes:\", classes)\n","\n","# -------------------\n","# 4) Rollout 준비 (레이어 핸들/토큰 추출)\n","# -------------------\n","def get_layer_safe(model, name=None, type_=None, start_after=None):\n","    if name is not None:\n","        try:\n","            return model.get_layer(name)\n","        except:\n","            pass\n","    if type_ is not None:\n","        layers_ = model.layers\n","        if start_after is not None:\n","            layers_ = layers_[model.layers.index(start_after)+1:]\n","        for l in layers_:\n","            if isinstance(l, type_): return l\n","    raise ValueError(f\"Layer not found: name={name}, type={type_}\")\n","\n","L = roll_model.layers\n","resnet = get_layer_safe(roll_model, name='resnet50')\n","conv_pe = get_layer_safe(roll_model, name='patch_embed_conv', type_=layers.Conv2D, start_after=resnet)\n","bn_pe   = get_layer_safe(roll_model, name='patch_embed_bn',   type_=layers.BatchNormalization)\n","gelu_pe = get_layer_safe(roll_model, name='patch_embed_gelu')\n","drop0   = get_layer_safe(roll_model, name='patch_embed_dropout', type_=layers.Dropout)\n","pos2d   = get_layer_safe(roll_model, name='pos2d', type_=PositionalEmbedding2D)\n","reshape = get_layer_safe(roll_model, name='tokens', type_=layers.Reshape)\n","drop_tk = get_layer_safe(roll_model, name='tokens_dropout', type_=layers.Dropout)\n","encoders = [l for l in L if isinstance(l, TransformerEncoder)]\n","assert encoders, \"TransformerEncoder 레이어를 찾지 못했습니다.\"\n","\n","@tf.function(jit_compile=False)\n","def tokens_from_image(x):  # x: [0,1]\n","    x = keras.applications.resnet.preprocess_input(x*255.0)\n","    f = resnet(x, training=False)\n","    t = conv_pe(f, training=False)\n","    t = bn_pe(t, training=False)\n","    t = gelu_pe(t)\n","    t = drop0(t, training=False)\n","    t = pos2d(t, training=False)\n","    H = tf.shape(t)[1]; W = tf.shape(t)[2]\n","    z = reshape(t); z = drop_tk(z, training=False)  # (B,T,D)\n","    return z, H, W\n","\n","# --- 안전 assert ---\n","def _assert_row_stochastic(A, atol=1e-4):  # A: (B,Tq,Tk)\n","    row_sum = tf.reduce_sum(A, axis=-1)\n","    tf.debugging.assert_near(row_sum, tf.ones_like(row_sum), atol=atol,\n","                             message=\"Attention rows must sum to 1 (row-stochastic).\")\n","\n","def _assert_grid_tokens(H, W, T):\n","    tf.debugging.assert_equal(tf.math.multiply(H, W), T,\n","                              message=\"Grid H*W must equal #tokens (reshape mismatch).\")\n","\n","# -------------------\n","# 5) 두상 마스크 + 마스크 내부 정규화 롤아웃\n","# -------------------\n","def brain_mask_smart(x, rel=0.20, min_thr=0.05, morph=2):\n","    \"\"\"x: [0,1] NHWC → 상대 임계 + 모폴로지 닫기로 두상 마스크\"\"\"\n","    g = tf.image.rgb_to_grayscale(x)                         # (B,H,W,1)\n","    vmax = tf.reduce_max(g, axis=[1,2,3], keepdims=True)\n","    thr  = tf.maximum(min_thr, rel * vmax)\n","    m = tf.cast(g > thr, tf.float32)                         # 0/1\n","\n","    k = 3\n","    for _ in range(morph):                                   # dilate\n","        m = tf.nn.max_pool2d(m, ksize=k, strides=1, padding='SAME')\n","    for _ in range(morph):                                   # erode\n","        m = 1.0 - tf.nn.max_pool2d(1.0 - m, ksize=k, strides=1, padding='SAME')\n","    return m                                                 # (B,H,W,1)\n","\n","def compute_rollout_map_masked(\n","    images, head_fuse='mean', use_residual=True,\n","    mask_rel=0.20, mask_min_thr=0.05, gamma=0.75\n","):\n","    images_tf = tf.convert_to_tensor(images, dtype=tf.float32) if isinstance(images, np.ndarray) else images\n","    z, H, W = tokens_from_image(images_tf)\n","    B = tf.shape(z)[0]; T = tf.shape(z)[1]\n","    _assert_grid_tokens(H, W, T)\n","\n","    # Rollout 누적\n","    R = tf.eye(T, batch_shape=[B])\n","    cur = z\n","    for enc in encoders:\n","        q = enc.n1(cur)\n","        attn_out, scores = enc.mha(q, q, return_attention_scores=True, training=False)  # (B, heads, T, T)\n","\n","        # 1) 수치 안정화 + 확률화(로짓이어도 OK)\n","        scores = tf.where(tf.math.is_finite(scores), scores, tf.zeros_like(scores))\n","        scores = tf.nn.softmax(scores, axis=-1)\n","\n","        # 2) head 융합\n","        if head_fuse == 'max':\n","            A = tf.reduce_max(scores, axis=1)     # (B, T, T)\n","        else:\n","            A = tf.reduce_mean(scores, axis=1)    # (B, T, T)\n","\n","        # 3) 융합 직후 행 정규화\n","        A = A / (tf.reduce_sum(A, axis=-1, keepdims=True) + 1e-6)\n","\n","        # 4) residual 추가 후 재정규화\n","        if use_residual:\n","            A = A + tf.eye(T, batch_shape=[B])\n","            A = A / (tf.reduce_sum(A, axis=-1, keepdims=True) + 1e-6)\n","\n","        # 5) 누적\n","        R = tf.linalg.matmul(R, A)\n","\n","        # 6) 트랜스포머 전진\n","        cur = cur + enc.d1(attn_out, training=False)\n","        h = enc.n2(cur); h = enc.mlp(h, training=False)\n","        cur = cur + h\n","\n","    # 토큰 중요도 → (B, H, W, 1) → 원 해상도 보간\n","    heat = tf.reduce_mean(R, axis=1)                          # (B,T)\n","    heat = tf.reshape(heat, (-1, H, W, 1))\n","    heat = tf.image.resize(heat, tf.shape(images_tf)[1:3], method='bilinear')\n","\n","    # 마스크 내부 기준 정규화\n","    m = brain_mask_smart(images_tf, rel=mask_rel, min_thr=mask_min_thr)      # (B,H,W,1)\n","    heat = heat * m\n","    very_neg = tf.constant(-1e9, heat.dtype)\n","    very_pos = tf.constant(1e9,  heat.dtype)\n","    hmax = tf.reduce_max(tf.where(m>0, heat, very_neg), axis=[1,2,3], keepdims=True)\n","    hmin = tf.reduce_min(tf.where(m>0, heat, very_pos), axis=[1,2,3], keepdims=True)\n","    heat = tf.clip_by_value((heat - hmin) / (hmax - hmin + 1e-8), 0., 1.)\n","    heat = tf.pow(heat, gamma)                                 # 스팟 강조\n","\n","    return heat.numpy()[..., 0], m.numpy()[..., 0]             # (B,H,W), (B,H,W)\n","\n","\n","def save_rollout_grid_masked(ds, mdl, classes, save_path, n=12, cols=6,\n","                             head_fuse='mean', mask_rel=0.20, mask_min_thr=0.05, gamma=0.75):\n","    # 샘플 뽑기\n","    xs, ys = [], []\n","    for x, y in ds.unbatch().take(n):\n","        xs.append(x.numpy()); ys.append(np.argmax(y.numpy()))\n","    xs = np.stack(xs, axis=0); ys = np.array(ys)\n","\n","    # 예측\n","    probs = mdl.predict(xs, verbose=0)\n","    preds = np.argmax(probs, axis=1)\n","\n","    # 히트맵 + 마스크\n","    heat, mask = compute_rollout_map_masked(xs, head_fuse=head_fuse,\n","                                            mask_rel=mask_rel, mask_min_thr=mask_min_thr, gamma=gamma)\n","\n","    # 그리드 렌더링 (배경 알파=0)\n","    rows = int(np.ceil(n/cols))\n","    fig, axes = plt.subplots(rows, cols, figsize=(3.4*cols, 3.6*rows))\n","    axes = np.array(axes).reshape(rows, cols)\n","    k = 0\n","    for r in range(rows):\n","        for c in range(cols):\n","            ax = axes[r, c]; ax.axis('off')\n","            if k < n:\n","                ax.imshow(xs[k])\n","                ax.imshow(heat[k], cmap='jet', alpha=0.45*mask[k])  # ★ 배경 투명\n","                gt = classes[ys[k]]; pd = classes[preds[k]]\n","                ax.set_title(f\"gt={gt} | pred={pd}\", fontsize=11)\n","                k += 1\n","    plt.tight_layout()\n","    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","    plt.savefig(save_path, dpi=200); plt.close()\n","\n","def rollout_diagnostics(ds, mdl, head_fuse='mean', n=48,\n","                        mask_rel=0.20, mask_min_thr=0.05, gamma=0.75):\n","    xs = np.stack([x.numpy() for x,_ in ds.unbatch().take(n)], axis=0)\n","    heat, mask = compute_rollout_map_masked(xs, head_fuse=head_fuse,\n","                                            mask_rel=mask_rel, mask_min_thr=mask_min_thr, gamma=gamma)\n","    inside = float((heat*mask).sum())\n","    total  = float(heat.sum() + 1e-8)\n","    brain_focus = inside/total\n","    # 토큰 그리드 진단\n","    z,H,W = tokens_from_image(tf.convert_to_tensor(xs, tf.float32))\n","    T = int(z.shape[1])\n","    print(f\"[diag] grid HxW={int(H.numpy())}x{int(W.numpy())}, T={T}, ok={int(H.numpy())*int(W.numpy())==T}\")\n","    print(f\"[diag] brain-focus ratio={brain_focus:.3f} (권장 ≥ 0.90)\")\n","    return brain_focus\n","\n","# -------------------\n","# 6) 예시: 그리드/진단 실행\n","# -------------------\n","grid_val = f\"{OUT}/rollout/val_rollout_grid_masked.png\"\n","save_rollout_grid_masked(val_ds, roll_model, classes, grid_val,\n","                         n=12, cols=6, head_fuse='max', mask_rel=0.20, mask_min_thr=0.05, gamma=0.75)\n","print(\"Saved:\", grid_val)\n","\n","# 원하면 test도\n","grid_test = f\"{OUT}/rollout/test_rollout_grid_masked.png\"\n","save_rollout_grid_masked(test_ds, roll_model, classes, grid_test,\n","                         n=12, cols=6, head_fuse='max', mask_rel=0.20, mask_min_thr=0.05, gamma=0.75)\n","print(\"Saved:\", grid_test)\n","\n","# 수치 진단\n","rollout_diagnostics(val_ds, roll_model, head_fuse='max', n=48,\n","                    mask_rel=0.20, mask_min_thr=0.05, gamma=0.75)\n","\n","# -------------------\n","# 7) TTA 성능 비교 (Test)\n","# -------------------\n","def five_crops(x, pad=16):\n","    H, W = x.shape[1], x.shape[2]\n","    x_pad = tf.pad(x, [[0,0],[pad,pad],[pad,pad],[0,0]], mode='REFLECT')\n","    crops = []\n","    crops.append(tf.image.crop_to_bounding_box(x_pad, 0, 0,     H, W))       # TL\n","    crops.append(tf.image.crop_to_bounding_box(x_pad, 0, 2*pad, H, W))       # TR\n","    crops.append(tf.image.crop_to_bounding_box(x_pad, 2*pad, 0, H, W))       # BL\n","    crops.append(tf.image.crop_to_bounding_box(x_pad, 2*pad, 2*pad, H, W))   # BR\n","    crops.append(tf.image.crop_to_bounding_box(x_pad, pad, pad, H, W))       # Center\n","    return crops\n","\n","def predict_tta(batch_x, policy, mdl):\n","    if policy == 'none':\n","        views = [batch_x]\n","    elif policy == 'hflip':\n","        views = [batch_x, tf.image.flip_left_right(batch_x)]\n","    elif policy == '5crop':\n","        views = five_crops(batch_x)\n","    elif policy == 'hflip+5crop':\n","        base = five_crops(batch_x); views = base + [tf.image.flip_left_right(c) for c in base]\n","    else:\n","        raise ValueError(\"unknown TTA policy\")\n","    probs = [mdl.predict(v, verbose=0) for v in views]\n","    return np.stack(probs, axis=0).mean(axis=0)\n","\n","def eval_ds_tta(ds, classes, policy, mdl):\n","    y_true, y_pred, probs = [], [], []\n","    n_img = 0; t0 = time.time()\n","    for x, y in ds:\n","        p = predict_tta(x, policy, mdl)\n","        probs.append(p)\n","        y_true.extend(np.argmax(y.numpy(), axis=1))\n","        y_pred.extend(np.argmax(p, axis=1))\n","        n_img += x.shape[0]\n","    dt = time.time() - t0\n","\n","    probs = np.concatenate(probs, 0)\n","    y_true = np.array(y_true); y_pred = np.array(y_pred)\n","    acc = accuracy_score(y_true, y_pred)\n","    mf1 = f1_score(y_true, y_pred, average='macro')\n","    auc = roc_auc_score(y_true, probs, multi_class='ovr', average='macro')\n","    ms_img = dt / n_img * 1000.0\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    print(f\"[TTA:{policy:11s}] acc={acc:.4f}  macroF1={mf1:.4f}  ROC-AUC={auc:.4f}  {ms_img:.1f} ms/img\")\n","    return acc, mf1, auc, ms_img, cm\n","\n","policies = ['none', 'hflip', '5crop', 'hflip+5crop']\n","rows = []; cms = {}\n","for pol in policies:\n","    acc, mf1, auc, ms, cm = eval_ds_tta(test_ds, classes, pol, roll_model)\n","    rows.append([pol, acc, mf1, auc, ms]); cms[pol] = cm\n","\n","csv_path = f\"{OUT}/tta_results.csv\"\n","with open(csv_path, \"w\", newline=\"\") as f:\n","    w = csv.writer(f); w.writerow([\"policy\",\"accuracy\",\"macro_f1\",\"roc_auc\",\"ms_per_image\"]); w.writerows(rows)\n","print(\"Saved CSV:\", csv_path)\n","\n","for pol, cm in cms.items():\n","    plt.figure(figsize=(5.6,4.8))\n","    plt.imshow(cm, cmap='Blues'); plt.title(f'Confusion Matrix (Test, {pol})'); plt.colorbar()\n","    ticks = np.arange(len(classes))\n","    plt.xticks(ticks, classes, rotation=45, ha='right'); plt.yticks(ticks, classes)\n","    for i in range(len(classes)):\n","        for j in range(len(classes)):\n","            v=cm[i,j]; c='white' if v>cm.max()/2 else 'black'\n","            plt.text(j,i,str(v),ha='center',va='center',color=c,fontsize=9)\n","    plt.tight_layout(); plt.savefig(f\"{OUT}/confmat_test_{pol}.png\", dpi=220); plt.close()\n","\n","print(\"Artifacts saved in:\", OUT)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"TdmGDckEDnNt"},"execution_count":null,"outputs":[]}]}